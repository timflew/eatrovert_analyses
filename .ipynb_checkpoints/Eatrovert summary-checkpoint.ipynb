{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Format data for app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import rauth\n",
    "import time\n",
    "import os \n",
    "import os.path \n",
    "import pickle as pkl\n",
    "\n",
    "import seaborn as sns\n",
    "from seaborn import heatmap\n",
    "sns.set(style=\"white\", color_codes=True)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import bokeh.plotting as plotting\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.charts import Bar, Scatter\n",
    "from bokeh.charts.attributes import cat,CatAttr\n",
    "from bokeh.io import gridplot\n",
    "\n",
    "from bokeh.io import output_file, show,output_notebook,save\n",
    "from bokeh.models import GMapPlot, GMapOptions, ColumnDataSource, Circle,Patch,Text, Range1d,DataRange1d, PanTool, WheelZoomTool, BoxSelectTool,HoverTool,ResetTool\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from scipy.spatial import ConvexHull\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_search_parameters(search_term,lat,lng,offset,num_search,search_mode):\n",
    "    #See the Yelp API for more details\n",
    "    params = {}\n",
    "    params[\"term\"] = search_term\n",
    "    params[\"sort\"]=str(search_mode)\n",
    "    params[\"offset\"] = str(offset)\n",
    "    params[\"ll\"] = \"{},{}\".format(str(lat),str(lng))\n",
    "    params[\"radius_filter\"] = \"20000\"\n",
    "    params[\"limit\"] = str(num_search)\n",
    "\n",
    "    return params\n",
    "\n",
    "def get_results(params):\n",
    "\n",
    "    #Obtain these from Yelp's manage access page\n",
    "    consumer_key = \"YOUR_CONSUMER_KEY\"\n",
    "    consumer_secret = \"YOUR_CONSUMER_SECRET\"\n",
    "    token = \"YOUR_TOKEN\"\n",
    "    token_secret = \"YOUR_TOKEN_SECRET\"\n",
    "\n",
    "    session = rauth.OAuth1Session(\n",
    "    consumer_key = consumer_key\n",
    "    ,consumer_secret = consumer_secret\n",
    "    ,access_token = token\n",
    "    ,access_token_secret = token_secret)\n",
    "\n",
    "    request = session.get(\"http://api.yelp.com/v2/search\",params=params)\n",
    "\n",
    "    #Transforms the JSON API response into a Python dictionary\n",
    "    data = request.json()\n",
    "    session.close()\n",
    "\n",
    "    return data\n",
    "\n",
    "def run_yelp_search(search_term,fname,locations,max_search,search_mode):\n",
    "    \n",
    "    try:\n",
    "        os.stat(fname)\n",
    "    except:\n",
    "        os.mkdir(fname) \n",
    "    \n",
    "    api_calls = []\n",
    "    offset=0\n",
    "    num_search=20\n",
    "\n",
    "    for lat,lng in locations:\n",
    "        loc_fold=os.path.join(fname,'loc'+str((int(lat*100),int(lng*100))))\n",
    "        try:\n",
    "            os.stat(loc_fold)\n",
    "        except:\n",
    "            os.mkdir(loc_fold) \n",
    "            \n",
    "        for its in range(max_search/num_search):\n",
    "            file_name=os.path.join(loc_fold,fname+str(its)+'.pkl')\n",
    "            if not os.path.exists(file_name):\n",
    "                params = get_search_parameters(search_term,lat,lng,offset,num_search,search_mode)\n",
    "                results=get_results(params)\n",
    "                api_calls.append(results)\n",
    "                offset=offset+num_search\n",
    "                #Be a good internet citizen and rate-limit yourself\n",
    "                print file_name\n",
    "                pkl.dump(results,open(file_name,'wb'))  \n",
    "                time.sleep(2.0)\n",
    "                clear_output()\n",
    "            else:\n",
    "                results=pkl.load(open(file_name,'rb'))\n",
    "                api_calls.append(results)\n",
    "    return api_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# San Diego: Downtown, La Jolla, National City, Miramesa, Kearny Mesa, North Park, Pacific Beach\n",
    "# Philadelphia: UPenn, City Hall, South Philadelphia, Temple University, Old City, West Philadelphia, Northern Liberties\n",
    "# New York: Holland Tunnel (not sure), Hell's Kitchen, Queens, Brooklyn, Flatiron, Chelsea, Gramercy, Time Square, Murray Hill\n",
    "# Chicago: Loop, UChicago, Archer Heights, Belmont, Pilsen, uptown, west loop\n",
    "# San Francisco: Nob Hill, Noe Valley, Inner Sunset, Inner Richmond, SOMA, Pacific Heights, The Mission\n",
    "\n",
    "# Lists of lattitudes and longitudes. I've only includes 2 for each city here\n",
    "city_locs={'San Diego':[(32.7157,-117.1611),(32.8328,-117.2713)],\n",
    "          'Philadelphia':[(39.9522,-75.1954),(39.9526,-75.1652)],\n",
    "          'New York':[(40.72512,-74.0113),(40.7612,-73.9887)],\n",
    "          'Chicago': [(41.8781,-87.6298),(41.7878,-87.6473)],\n",
    "          'San Francisco':[(37.7823,-122.4219),(37.7504,-122.4304)]}\n",
    "\n",
    "city_abbreb={'San Diego':'sd',\n",
    "             'Philadelphia':'ph',\n",
    "             'New York':'ny',\n",
    "             'Chicago':'ch',\n",
    "             'San Francisco':'sf'}\n",
    "\n",
    "city_zoom={'San Diego':(32.7157,-117.1611),\n",
    "           'Philadelphia':(39.9526,-75.1652),\n",
    "           'New York':(40.7612,-73.9887),\n",
    "          'Chicago':(41.8781,-87.6298),\n",
    "           'San Francisco':(37.7823,-122.4219)}\n",
    "\n",
    "cities=city_zoom.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "foldname='processed_data'\n",
    "if not os.path.isdir(foldname):\n",
    "    os.mkdir(foldname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After I scraped all the data, I stored it all into a dataframe. But the category labels needed some cleaning. I think there's room for improvement here. Apart from pizza, I only used information from the first category label Yelp provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_calls=[]\n",
    "all_city=[]\n",
    "for city in city_locs.keys():\n",
    "    search_term='food'\n",
    "    max_search=1000\n",
    "    locations=city_locs[city]\n",
    "    \n",
    "    # search be best match\n",
    "    fname=city_abbreb[city]+'_food_search'\n",
    "    \n",
    "    curr_calls=run_yelp_search(search_term,fname,locations,max_search,0)\n",
    "\n",
    "    # search by distance\n",
    "    search_term='food'\n",
    "    fname=city_abbreb[city]+'_food_search_dist'\n",
    "    max_search=1000\n",
    "    curr_calls_dist=run_yelp_search(search_term,fname,locations,max_search,1)\n",
    "    all_calls=all_calls+curr_calls+curr_calls_dist\n",
    "    all_city=all_city+([city]*len(curr_calls+curr_calls_dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def api_call_to_df(food_calls,all_city):\n",
    "    all_name=[]\n",
    "    all_rating=[]\n",
    "    all_lat=[]\n",
    "    all_lng=[]\n",
    "    all_cat=[]\n",
    "    all_cities=[]    \n",
    "    all_num_rev=[]\n",
    "    all_price=[]\n",
    "    for call,city in zip(food_calls,all_city):\n",
    "\n",
    "        try:\n",
    "            business_data=call['businesses']\n",
    "            all_lat=all_lat+[business_data[i]['location']['coordinate']['latitude'] for i in range(len(business_data))]\n",
    "            all_lng=all_lng+[business_data[i]['location']['coordinate']['longitude'] for i in range(len(business_data))]\n",
    "            all_name=all_name+[business_data[i]['name'] for i in range(len(business_data))]\n",
    "            \n",
    "            # trying to split up pizza\n",
    "            curr_cat=[]\n",
    "            for i in range(len(business_data)):\n",
    "                if (business_data[i]['categories'][0][1]=='pizza'):\n",
    "                    if len(business_data[i]['categories'])>1:\n",
    "                        curr_cat.append('pizza_plus')\n",
    "                    else:\n",
    "                        curr_cat.append('pizza')\n",
    "                else:\n",
    "                    curr_cat.append(business_data[i]['categories'][0][1])\n",
    "                    \n",
    "            all_cat=all_cat+curr_cat\n",
    "                \n",
    "#            all_cat=all_cat+[business_data[i]['categories'][0][1] for i in range(len(business_data))]\n",
    "            all_rating=all_rating+[business_data[i]['rating'] for i in range(len(business_data))]\n",
    "            all_num_rev=all_num_rev+[business_data[i]['review_count'] for i in range(len(business_data))]  \n",
    "            all_price=all_price+[business_data[i]['review_count'] for i in range(len(business_data))]              \n",
    "            all_cities=all_cities+([city]*len(business_data))\n",
    "            \n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    return pd.DataFrame({'Name':all_name,'Cat':all_cat, 'Rating':all_rating,\n",
    "                         'Lat':all_lat,'Lng':all_lng,'City':all_cities,'Num_Rev':all_num_rev})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_dataframe(rest_df):\n",
    "\n",
    "    rest_df.loc[rest_df.Cat=='beer_and_wine','Cat']='beer'\n",
    "    rest_df.loc[rest_df.Cat=='bars','Cat']='beer'\n",
    "    rest_df.loc[rest_df.Cat=='beergardens','Cat']='beer'\n",
    "    rest_df.loc[rest_df.Cat=='breweries','Cat']='beer'\n",
    "    rest_df.loc[rest_df.Cat=='gastropubs','Cat']='beer'\n",
    "    rest_df.loc[rest_df.Cat=='divebars','Cat']='beer'  \n",
    "    rest_df.loc[rest_df.Cat=='pubs','Cat']='beer'\n",
    "    rest_df.loc[rest_df.Cat=='sportsbars','Cat']='beer' \n",
    "    rest_df.loc[rest_df.Cat=='beerbar','Cat']='beer'       \n",
    "    rest_df.loc[rest_df.Cat=='wine','Cat']='wine'\n",
    "    rest_df.loc[rest_df.Cat=='wine_bars','Cat']='wine'\n",
    "    rest_df.loc[rest_df.Cat=='champagne_bars','Cat']='wine'\n",
    "    rest_df.loc[rest_df.Cat=='cocktailbars','Cat']='cocktails'\n",
    "    rest_df.loc[rest_df.Cat=='lounges','Cat']='cocktails'\n",
    "\n",
    "    # Coffee sort of places\n",
    "    rest_df.loc[rest_df.Cat=='tea','Cat']='cafes'\n",
    "    rest_df.loc[rest_df.Cat=='coffee','Cat']='cafes'\n",
    "    rest_df.loc[rest_df.Cat=='bubbletea','Cat']='cafes'    \n",
    "\n",
    "    # hotdog\n",
    "    rest_df.loc[rest_df.Cat=='hotdogs','Cat']='hotdog'\n",
    "\n",
    "    # healthy things...don't yell at me...\n",
    "    rest_df.loc[rest_df.Cat=='vegan','Cat']='vegetarian'\n",
    "    rest_df.loc[rest_df.Cat=='juicebars','Cat']='vegetarian'\n",
    "    rest_df.loc[rest_df.Cat=='organic_stores','Cat']='vegetarian'\n",
    "    rest_df.loc[rest_df.Cat=='gluten_free','Cat']='vegetarian'  \n",
    "    rest_df.loc[rest_df.Cat=='raw_food','Cat']='vegetarian'  \n",
    "    rest_df.loc[rest_df.Cat=='healthmarkets','Cat']='vegetarian'  \n",
    "    rest_df.loc[rest_df.Cat=='diyfood','Cat']='vegetarian'      \n",
    "\n",
    "    # cupcakes->bakeries\n",
    "    rest_df.loc[rest_df.Cat=='cupcakes','Cat']='bakeries'\n",
    "\n",
    "    # group tapas\n",
    "    rest_df.loc[rest_df.Cat=='tapasmallplates','Cat']='tapas'\n",
    "\n",
    "    # ice cream->desserts\n",
    "    rest_df.loc[rest_df.Cat=='icecream','Cat']='desserts'\n",
    "    rest_df.loc[rest_df.Cat=='creperies','Cat']='desserts'\n",
    "    rest_df.loc[rest_df.Cat=='donuts','Cat']='desserts'\n",
    "    rest_df.loc[rest_df.Cat=='gelato','Cat']='desserts'\n",
    "    rest_df.loc[rest_df.Cat=='chocolate','Cat']='desserts'    \n",
    "\n",
    "    # fishnchips->british\n",
    "    rest_df.loc[rest_df.Cat=='fishnchips','Cat']='british'\n",
    "    rest_df.loc[rest_df.Cat=='cantonese','Cat']='chinese'  \n",
    "    rest_df.loc[rest_df.Cat=='shanghainese','Cat']='chinese' \n",
    "    rest_df.loc[rest_df.Cat=='dimsum','Cat']='chinese'  \n",
    "    \n",
    "    rest_df.loc[rest_df.Cat=='falafel','Cat']='mideastern'\n",
    "    rest_df.loc[rest_df.Cat=='halal','Cat']='mideastern'   \n",
    "    rest_df.loc[rest_df.Cat=='chickenshop','Cat']='soulfood' \n",
    "    rest_df.loc[rest_df.Cat=='steak','Cat']='newamerican' \n",
    "    rest_df.loc[rest_df.Cat=='southern','Cat']='comfortfood'\n",
    "    rest_df.loc[rest_df.Cat=='fondue','Cat']='newamerican' \n",
    "    rest_df.loc[rest_df.Cat=='empanadas','Cat']='argentine' \n",
    "    rest_df.loc[rest_df.Cat=='brasseries','Cat']='tradamerican'   \n",
    "    rest_df.loc[rest_df.Cat=='teppanyaki','Cat']='japanese'    \n",
    "    rest_df.loc[rest_df.Cat=='sushi','Cat']='japanese' \n",
    "    rest_df.loc[rest_df.Cat=='hotpot','Cat']='chinese'           \n",
    "\n",
    "    # Non-descriptive labels\n",
    "    rest_df=rest_df.drop(rest_df.index[rest_df.Cat=='farmersmarket'])\n",
    "    rest_df=rest_df.drop(rest_df.index[rest_df.Cat=='venues'])\n",
    "    rest_df=rest_df.drop(rest_df.index[rest_df.Cat=='convenience'])\n",
    "    rest_df=rest_df.drop(rest_df.index[rest_df.Cat=='restaurants'])\n",
    "    rest_df=rest_df.drop(rest_df.index[rest_df.Cat=='fooddeliveryservices'])\n",
    "    rest_df=rest_df.drop(rest_df.index[rest_df.Cat=='food_court'])\n",
    "    rest_df=rest_df.drop(rest_df.index[rest_df.Cat=='seafoodmarkets'])\n",
    "    rest_df=rest_df.drop(rest_df.index[rest_df.Cat=='catering'])\n",
    "    rest_df=rest_df.drop(rest_df.index[rest_df.Cat=='soup'])\n",
    "    rest_df=rest_df.drop(rest_df.index[rest_df.Cat=='foodtrucks'])    \n",
    "    rest_df=rest_df.drop(rest_df.index[rest_df.Cat=='gourmet'])\n",
    "    rest_df=rest_df.drop(rest_df.index[rest_df.Cat=='meats'])\n",
    "    rest_df=rest_df.drop(rest_df.index[rest_df.Cat=='grocery'])\n",
    "    rest_df=rest_df.drop(rest_df.index[rest_df.Cat=='cheese'])\n",
    "    rest_df=rest_df.drop(rest_df.index[rest_df.Cat=='streetvendors'])\n",
    "    rest_df=rest_df.drop(rest_df.index[rest_df.Cat=='movietheaters'])\n",
    "    rest_df=rest_df.drop(rest_df.index[rest_df.Cat=='foodstands'])\n",
    "    rest_df=rest_df.drop(rest_df.index[rest_df.Cat=='buffets'])   \n",
    "    rest_df=rest_df.drop(rest_df.index[rest_df.Cat=='banks']) \n",
    "    rest_df=rest_df.drop(rest_df.index[rest_df.Cat=='galleries'])  \n",
    "    rest_df=rest_df.drop(rest_df.index[rest_df.Cat=='butcher']) \n",
    "    rest_df=rest_df.drop(rest_df.index[rest_df.Cat=='musicvenues'])  \n",
    "    rest_df=rest_df.drop(rest_df.index[rest_df.Cat=='cafeteria'])      \n",
    "    rest_df=rest_df.drop(rest_df.index[rest_df.Cat=='tours'])   \n",
    "    rest_df=rest_df.drop(rest_df.index[rest_df.Cat=='jazzandblues'])       \n",
    "    rest_df=rest_df.drop(rest_df.index[rest_df.Cat=='ethnicmarkets'])   \n",
    "    rest_df=rest_df.drop(rest_df.index[rest_df.Cat=='arcades'])       \n",
    "    rest_df=rest_df.drop(rest_df.index[rest_df.Cat=='food']) \n",
    "    rest_df=rest_df.drop(rest_df.index[rest_df.Cat=='hotels'])    \n",
    "    rest_df=rest_df.drop(rest_df.index[rest_df.Cat=='delis'])\n",
    "    rest_df=rest_df.drop(rest_df.index[rest_df.Cat=='hookah_bars'])  \n",
    "    rest_df=rest_df.drop(rest_df.index[rest_df.Cat=='sandwiches'])  # only used in sf for some reason\n",
    "    \n",
    "    return rest_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_rest_df=api_call_to_df(all_calls,all_city)\n",
    "all_rest_df=clean_dataframe(all_rest_df)\n",
    "all_rest_df=all_rest_df.drop_duplicates(subset=['Name','Lng','Lat']).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_rest_df.Name=all_rest_df.Name.apply(lambda x:x.encode(\"utf-8\")) # accent encoding issue\n",
    "all_rest_df.to_csv(os.path.join(foldname,'city_all.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KL divergence Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I'm going to count how many restaurants of each type there are in each city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_cat_distr(rest_df):\n",
    "    rest_df_count=rest_df.groupby('Cat').size().sort_values(ascending=False).reset_index()\n",
    "    rest_df_rating_mean=rest_df.loc[:,['Cat','Rating']].groupby('Cat').mean().reset_index()\n",
    "    \n",
    "    rest_df2=pd.merge(rest_df_count,rest_df_rating_mean,on='Cat')\n",
    "    rest_df2.columns=['Category','Count','Rating']\n",
    "    return rest_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_cat_count=all_rest_df.groupby(['City','Cat']).size().reset_index()\n",
    "all_cat_count.columns=['City','Category','Count']\n",
    "all_cat_rating=all_rest_df.loc[:,['City','Cat','Rating']].groupby(['City','Cat']).mean().reset_index()\n",
    "all_cat_rating.columns=['City','Category','Rating']\n",
    "all_cat_count=pd.merge(all_cat_count,all_cat_rating,on=['City','Category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now I'm going to add entries for restaurant categories that aren't in certain cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "categories=np.unique(all_rest_df.Cat)\n",
    "all_city_count_df = pd.DataFrame(columns=['City','Category','Count','Rating'])\n",
    "for key in cities:\n",
    "    temp=all_cat_count.loc[all_cat_count.City==key,:]\n",
    "    for cat in categories:\n",
    "        if sum(np.logical_and(temp.Category==cat,temp.City==key))==0:\n",
    "            temp=temp.append(pd.DataFrame({'City':[key],'Category':[cat],'Count':[0]}))\n",
    "    all_city_count_df=all_city_count_df.append(temp)\n",
    "\n",
    "all_city_count_df.Count=all_city_count_df.Count+1 # Prevent divide by zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally we can turn this into KL divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/timlew/anaconda/lib/python2.7/site-packages/pandas/core/indexing.py:284: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/Users/timlew/anaconda/lib/python2.7/site-packages/pandas/core/indexing.py:461: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "city_pair_kl = pd.DataFrame(columns=['City_a','City_b','Category','KL Divergence','Rating Difference'])\n",
    "for a_c in cities:\n",
    "    for b_c in cities:\n",
    "        if a_c!=b_c:\n",
    "            # Calculate proportion of restaurant distribution\n",
    "            a_subset=all_city_count_df.loc[all_city_count_df.City==a_c,:]\n",
    "            a_subset.loc[:,'a_Prop']=a_subset.loc[:,'Count']/sum(a_subset.loc[:,'Count'])\n",
    "            b_subset=all_city_count_df.loc[all_city_count_df.City==b_c,:]            \n",
    "            b_subset.loc[:,'b_Prop']=b_subset.loc[:,'Count']/sum(b_subset.loc[:,'Count'])\n",
    "\n",
    "            ab_merge_df=pd.merge(a_subset,b_subset,on=['Category'],suffixes=('_a','_b'))\n",
    "            ab_merge_df.loc[:,'KL Divergence']=ab_merge_df.a_Prop*np.log10(ab_merge_df.loc[:,'a_Prop']/ab_merge_df.loc[:,'b_Prop'])\n",
    "            ab_merge_df.loc[:,'Rating Difference']=ab_merge_df.Rating_a-ab_merge_df.Rating_b\n",
    "\n",
    "            city_pair_kl=city_pair_kl.append(ab_merge_df.loc[:,['City_a','City_b','Category', 'KL Divergence','Rating Difference']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "city_pair_kl.to_csv(os.path.join(foldname,'city_kl.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making figures!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now let's do some analyses!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "foldname='example_figs'\n",
    "if not os.path.isdir(foldname):\n",
    "    os.mkdir(foldname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## City maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where were our restaurants located?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_map_distr(rest_df,city,coords,zoom):\n",
    "\tmap_options = GMapOptions(lat=coords[0], lng=coords[1], map_type=\"roadmap\", zoom=zoom)\n",
    "\tplot = GMapPlot(x_range=DataRange1d(), y_range=DataRange1d(), map_options=map_options, title=\"San Diego\")\n",
    "\n",
    "\n",
    "\trest_source = ColumnDataSource(data=dict(lat=rest_df.Lat,lon=rest_df.Lng,Name=rest_df.Name,Rating=rest_df.Rating))\n",
    "\trest_circle = Circle(x=\"lon\", y=\"lat\", size=5, fill_color='dodgerblue', fill_alpha=0.8, line_color='lightslategrey')\n",
    "\tplot.add_glyph(rest_source, rest_circle)\n",
    "\thover = HoverTool( tooltips=[(\"Name\", \"@Name\"),('Rating','@Rating')])\n",
    "\t\t\n",
    "\tplot.add_tools(PanTool(), WheelZoomTool(), BoxSelectTool(),ResetTool(),hover)\n",
    "\treturn plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "city='San Francisco'\n",
    "plot=plot_map_distr(all_rest_df,city,city_zoom[city],zoom=11)\n",
    "fname=city+'_map'+'.html'\n",
    "full_name=os.path.join(foldname,fname)\n",
    "output_file(full_name)\n",
    "show(plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## City distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What was the distribution of restaurant categories within each city?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_category_distr(rest_df,city):\n",
    "    rest_df=rest_df.loc[rest_df.City==city,:]\n",
    "    rest_df=get_cat_distr(rest_df)\n",
    "\n",
    "    plot=Bar(rest_df,label=CatAttr(columns=['Category'], sort=False),values='Count',plot_width=1200, plot_height=500)\n",
    "    return plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "city='San Francisco'\n",
    "plot=plot_category_distr(all_rest_df,city)\n",
    "fname=city+'_distribution'+'.html'\n",
    "full_name=os.path.join(foldname,fname)\n",
    "output_file(full_name)\n",
    "show(plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kullback-Leibler convergence-Aggregate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How different are the other cities?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_similar_city(kl_df,visitor):\n",
    "\tmean_visited=kl_df.loc[kl_df.loc[:,'City_b']==visitor,['City_a','KL Divergence']].groupby('City_a').sum().reset_index()\n",
    "\tmean_visited=mean_visited.sort_values(by='KL Divergence',ascending=False)\n",
    "\tmean_visited.columns=['City','KL Divergence']\n",
    "\tplot=Bar(mean_visited,label=CatAttr(columns=['City'], sort=False),values='KL Divergence',plot_width=800, plot_height=300)\n",
    "\t\n",
    "\treturn plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "visitor='San Diego'\n",
    "plot=plot_similar_city(city_pair_kl,visitor)\n",
    "fname=city+'_kl_aggr'+'.html'\n",
    "full_name=os.path.join(foldname,fname)\n",
    "output_file(full_name)\n",
    "show(plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kullback-Leibler convergence-By category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What categories do restaurants vary in?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_frequent_city(kl_df,visitor,visited):\n",
    "    sel_city_pair=np.logical_and(kl_df.City_a==visited, kl_df.City_b==visitor)\n",
    "    curr_city=kl_df.loc[sel_city_pair,:]\n",
    "    curr_city=curr_city.sort_values(by='KL Divergence',ascending=False)\n",
    "    plot=Bar(curr_city,label=CatAttr(columns=['Category'], sort=False),values='KL Divergence',plot_width=1200, plot_height=600,title='From '+visitor+' To '+visited)\n",
    "    return plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "visitor='San Diego'\n",
    "visited='New York'\n",
    "plot=plot_frequent_city(city_pair_kl,visitor,visited)\n",
    "fname=visitor+'_'+visited+'_kl_ind'+'.html'\n",
    "full_name=os.path.join(foldname,fname)\n",
    "output_file(full_name)\n",
    "show(plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Novel restaurant map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where should you go if you want novel foods?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "two_pt_five_in_degrees=(float(1)/70)*2.5\n",
    "two_in_degrees=(float(1)/70)*2\n",
    "one_pt_five_in_degrees=(float(1)/70)*1.5\n",
    "mile_in_degrees=(float(1)/70)\n",
    "threequarter_in_degrees=(float(1)/70)/(float(4)/3)\n",
    "twothird_in_degrees=(float(1)/70)/1.5\n",
    "half_mile_in_degrees=(float(1)/70)/2\n",
    "quarter_mile_in_degrees=(float(1)/70)/4\n",
    "\n",
    "eps_range={'San Francisco':{'gen':quarter_mile_in_degrees,'clus':threequarter_in_degrees},'San Diego':{'gen':twothird_in_degrees,'clus':mile_in_degrees},'Philadelphia':{'gen':twothird_in_degrees,'clus':two_pt_five_in_degrees},'New York':{'gen':half_mile_in_degrees,'clus':mile_in_degrees},'Chicago':{'gen':quarter_mile_in_degrees,'clus':mile_in_degrees}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cluster_locations(df,eps,min_s):\n",
    "    km_clus=DBSCAN(eps=eps,min_samples=min_s)\n",
    "    labels=km_clus.fit_predict(df.loc[:,['Lat','Lng']])\n",
    "    return labels\n",
    "    \n",
    "def rest_rank(df,cat_name):\n",
    "    df=df.sort_values(by=['Num_Rev','Rating'],ascending=False)\n",
    "    p = figure(toolbar_location=None)\n",
    "    p.set(x_range=Range1d(-.2, 4), y_range=Range1d(-11,2))\n",
    "\n",
    "    y=0\n",
    "\n",
    "    # Category name\n",
    "    p.text(0, y, text=[cat_name],text_color=\"darkred\", text_align=\"left\", text_font_size=str(32)+\"pt\",text_font='impact')\n",
    "\n",
    "    t_size=15\n",
    "    count=0\n",
    "    for i,row in df.iterrows():\n",
    "        y=y-2\n",
    "        name=row.loc['Name']+', '+str(row.loc['Rating'])\n",
    "        p.text(0, y, text=[name],text_color=\"indianred\", text_align=\"left\", text_font_size=str(t_size)+\"pt\",text_font='Arial Black')\n",
    "        name2='# Reviews: '+str(row.loc['Num_Rev'])\n",
    "        p.text(0, y-.5, text=[name2],text_color=\"indianred\", text_align=\"left\", text_font_size=\"14pt\",text_font='Arial Black')\n",
    "\n",
    "    # \t\tt_size=t_size-2\n",
    "        count=count+1\n",
    "        if count>4:\n",
    "            break\n",
    "    p.axis.visible=None\n",
    "    p.xgrid.grid_line_color = None\n",
    "    p.ygrid.grid_line_color = None\n",
    "    return p\n",
    "\n",
    "\n",
    "def plot_map_clusters(city_visited,city_visitor,city_pair_kl,all_rest_df,eps_gen,eps_clus,num_freq,coords):\n",
    "    curr_city=all_rest_df.loc[all_rest_df.loc[:,'City']==city_visited,:]\n",
    "\n",
    "    def match_cat(row):\n",
    "        if row.Cat in novel_cats2:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    # Center map on restaurants in category\n",
    "    i=num_freq\n",
    "    sel_ind_cat=np.logical_and(city_pair_kl.loc[:,'City_a']==city_visited, city_pair_kl.loc[:,'City_b']==city_visitor)\n",
    "\n",
    "    novel_cats=city_pair_kl.loc[sel_ind_cat,:].sort_values(by='KL Divergence',ascending=False).iloc[i,:]\n",
    "    novel_cats2=novel_cats.loc[:,'Category'].tolist()#[novel_cats.Category]\n",
    "    cat_match=curr_city.apply(match_cat,axis=1)\n",
    "    subset_rest_df=curr_city.loc[cat_match,:]\n",
    "\n",
    "    clus_lat=subset_rest_df.loc[:,'Lat'].mean()\n",
    "    clus_lng=subset_rest_df.loc[:,'Lng'].mean()\n",
    "\n",
    "    # actual map\n",
    "    map_options = GMapOptions(lat=clus_lat, lng=clus_lng, map_type=\"roadmap\", zoom=11)\n",
    "    plot = GMapPlot(x_range=DataRange1d(), y_range=DataRange1d(), map_options=map_options)\n",
    "\n",
    "    # Identify novel restaurants so we can remove them from the general clustering\n",
    "    sel_ind_cat=np.logical_and(city_pair_kl.loc[:,'City_a']==city_visited, city_pair_kl.loc[:,'City_b']==city_visitor)\n",
    "\n",
    "    novel_cats=city_pair_kl.loc[sel_ind_cat,:].sort_values(by='KL Divergence',ascending=False).iloc[i,:]\n",
    "    novel_cats2=novel_cats.loc[:,'Category'].tolist()\n",
    "\n",
    "    cat_match=curr_city.apply(match_cat,axis=1)\n",
    "    subset_rest_df=curr_city.loc[np.logical_not(cat_match),:]\n",
    "\n",
    "    # Identify clusters\n",
    "    subset_rest_df.loc[:,'Clus']=cluster_locations(subset_rest_df,eps=eps_gen,min_s=10)\n",
    "\n",
    "\n",
    "    # Turn general clusters into convex hull and add patches to map\n",
    "    curr_clus=np.unique(subset_rest_df.loc[:,'Clus'])\n",
    "    curr_clus=curr_clus[curr_clus>=0]\n",
    "    for cp in curr_clus:\n",
    "        subset_rest_df2=subset_rest_df.loc[subset_rest_df.loc[:,'Clus']==cp,:]\n",
    "        try:\n",
    "            hull_points=ConvexHull(subset_rest_df2.loc[:,['Lat','Lng']]).vertices\n",
    "            hull_locs=subset_rest_df2.iloc[hull_points,:].loc[:,['Lat','Lng']]\n",
    "            cp_source=ColumnDataSource(data=dict(lat=hull_locs.loc[:,'Lat'],lon=hull_locs.loc[:,'Lng']))\n",
    "            cp_patch=Patch(x=\"lon\",y=\"lat\", fill_color='dodgerblue', line_color='lightslategrey',fill_alpha=.2)\n",
    "            plot.add_glyph(cp_source, cp_patch)      \n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # For given categories, cluster and plot\n",
    "    colors=['indianred','mediumseagreen','gold']\n",
    "    i=num_freq\n",
    "    sel_ind_cat=np.logical_and(city_pair_kl.loc[:,'City_a']==city_visited, city_pair_kl.loc[:,'City_b']==city_visitor)\n",
    "    novel_cats=city_pair_kl.loc[sel_ind_cat,:].sort_values(by='KL Divergence',ascending=False).iloc[i,:]\n",
    "    novel_cats2=novel_cats.loc[:,'Category'].tolist()#[novel_cats.Category]\n",
    "    cat_match=curr_city.apply(match_cat,axis=1)\n",
    "    subset_rest_df=curr_city.loc[cat_match,:]\n",
    "\n",
    "    # Identify clusters\n",
    "    subset_rest_df.loc[:,'Clus']=cluster_locations(subset_rest_df,eps=eps_clus,min_s=3)\n",
    "\n",
    "    # Turn novel clusters into convex hull and add patches to map\n",
    "    curr_clus=np.unique(subset_rest_df.loc[:,'Clus'])\n",
    "    curr_clus=curr_clus[curr_clus>=0]\n",
    "\n",
    "    for cp in curr_clus:\n",
    "        subset_rest_df2=subset_rest_df.loc[subset_rest_df.loc[:,'Clus']==cp,:]\n",
    "\n",
    "        cat_props=subset_rest_df2.groupby('Cat').size().reset_index()\n",
    "        cat_props.columns=['Category','Number']\n",
    "        try:\n",
    "            hull_points=ConvexHull(subset_rest_df2.loc[:,['Lat','Lng']]).vertices\n",
    "            hull_locs=subset_rest_df2.iloc[hull_points,:].loc[:,['Lat','Lng']]\n",
    "            cp_source=ColumnDataSource(data=dict(lat=hull_locs.loc[:,'Lat'],lon=hull_locs.loc[:,'Lng']))\n",
    "            cp_patch=Patch(x=\"lon\",y=\"lat\", fill_color='indianred', line_color='lightslategrey',fill_alpha=.5)\n",
    "            plot.add_glyph(cp_source, cp_patch)\n",
    "        except:\n",
    "            pass  \n",
    "\n",
    "    subset_rest_df_rank=subset_rest_df.sort_values(by=['Num_Rev','Rating'],ascending=False).iloc[0:5,:]\n",
    "    rest_source = ColumnDataSource(data=dict(lat=subset_rest_df_rank.loc[:,'Lat'],lon=subset_rest_df_rank.loc[:,'Lng'],Name=subset_rest_df_rank.loc[:,'Name'],Rating=subset_rest_df_rank.loc[:,'Rating']))\n",
    "    rest_circle = Circle(x=\"lon\", y=\"lat\", size=10, fill_color=colors[0], fill_alpha=0.8, line_color='lightslategrey')\n",
    "    plot.add_glyph(rest_source, rest_circle)\n",
    "    hover = HoverTool( tooltips=[(\"Name\", \"@Name\"),('Rating','@Rating')])\n",
    "\n",
    "    plot.add_tools(PanTool(), WheelZoomTool(), BoxSelectTool(),ResetTool(),hover)\n",
    "\n",
    "    # Plot text rank\n",
    "    text_plot=rest_rank(subset_rest_df,novel_cats2[0].upper())\n",
    "\n",
    "    return plot,text_plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "visitor='San Diego'\n",
    "visited='New York'\n",
    "vis_plot=[]\n",
    "for freq in range(0,5):\n",
    "    curr_plot,curr_text=plot_map_clusters(visited,visitor,city_pair_kl,all_rest_df,eps_gen=eps_range[visited]['gen'],eps_clus=eps_range[visited]['clus'],num_freq=[freq],coords=city_locs[visited])\n",
    "    vis_plot.append([curr_plot,curr_text])\n",
    "vis_plot=gridplot(vis_plot)\n",
    "\n",
    "fname=visitor+'_'+visited+'_diff_map'+'.html'\n",
    "full_name=os.path.join(foldname,fname)\n",
    "output_file(full_name)\n",
    "show(vis_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similar restaurant maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where should you go if you want food that's similar to home?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_same_map_clusters(city_visited,city_visitor,city_pair_kl,all_rest_df,eps_gen,eps_clus,num_freq,coords):\n",
    "    curr_city=all_rest_df.loc[all_rest_df.loc[:,'City']==city_visited,:]\n",
    "\n",
    "    def match_cat(row):\n",
    "        if row.Cat in novel_cats2:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    # Center map on restaurants in category\n",
    "    i=num_freq\n",
    "    sel_ind_cat=np.logical_and(city_pair_kl.loc[:,'City_a']==city_visited, city_pair_kl.loc[:,'City_b']==city_visitor)\n",
    "\n",
    "    novel_cats=city_pair_kl.loc[sel_ind_cat,:].sort_values(by='KL Divergence',ascending=True).iloc[i,:]\n",
    "    novel_cats2=novel_cats.loc[:,'Category'].tolist()#[novel_cats.Category]\n",
    "    cat_match=curr_city.apply(match_cat,axis=1)\n",
    "    subset_rest_df=curr_city.loc[cat_match,:]\n",
    "\n",
    "    clus_lat=subset_rest_df.loc[:,'Lat'].mean()\n",
    "    clus_lng=subset_rest_df.loc[:,'Lng'].mean()\n",
    "\n",
    "    # actual map\n",
    "    map_options = GMapOptions(lat=clus_lat, lng=clus_lng, map_type=\"roadmap\", zoom=11)\n",
    "    plot = GMapPlot(x_range=DataRange1d(), y_range=DataRange1d(), map_options=map_options)\n",
    "\n",
    "    # Identify novel restaurants so we can remove them from the general clustering\n",
    "    sel_ind_cat=np.logical_and(city_pair_kl.loc[:,'City_a']==city_visited, city_pair_kl.loc[:,'City_b']==city_visitor)\n",
    "\n",
    "    novel_cats=city_pair_kl.loc[sel_ind_cat,:].sort_values(by='KL Divergence',ascending=True).iloc[i,:]\n",
    "    novel_cats2=novel_cats.loc[:,'Category'].tolist()\n",
    "\n",
    "    cat_match=curr_city.apply(match_cat,axis=1)\n",
    "    subset_rest_df=curr_city.loc[np.logical_not(cat_match),:]\n",
    "\n",
    "    # Identify clusters\n",
    "    subset_rest_df.loc[:,'Clus']=cluster_locations(subset_rest_df,eps=eps_gen,min_s=10)\n",
    "\n",
    "\n",
    "    # Turn general clusters into convex hull and add patches to map\n",
    "    curr_clus=np.unique(subset_rest_df.loc[:,'Clus'])\n",
    "    curr_clus=curr_clus[curr_clus>=0]\n",
    "    for cp in curr_clus:\n",
    "        subset_rest_df2=subset_rest_df.loc[subset_rest_df.loc[:,'Clus']==cp,:]\n",
    "        try:\n",
    "            hull_points=ConvexHull(subset_rest_df2.loc[:,['Lat','Lng']]).vertices\n",
    "            hull_locs=subset_rest_df2.iloc[hull_points,:].loc[:,['Lat','Lng']]\n",
    "            cp_source=ColumnDataSource(data=dict(lat=hull_locs.loc[:,'Lat'],lon=hull_locs.loc[:,'Lng']))\n",
    "            cp_patch=Patch(x=\"lon\",y=\"lat\", fill_color='dodgerblue', line_color='lightslategrey',fill_alpha=.2)\n",
    "            plot.add_glyph(cp_source, cp_patch)      \n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # For given categories, cluster and plot\n",
    "    colors=['indianred','mediumseagreen','gold']\n",
    "    i=num_freq\n",
    "    sel_ind_cat=np.logical_and(city_pair_kl.loc[:,'City_a']==city_visited, city_pair_kl.loc[:,'City_b']==city_visitor)\n",
    "    novel_cats=city_pair_kl.loc[sel_ind_cat,:].sort_values(by='KL Divergence',ascending=True).iloc[i,:]\n",
    "    novel_cats2=novel_cats.loc[:,'Category'].tolist()#[novel_cats.Category]\n",
    "    cat_match=curr_city.apply(match_cat,axis=1)\n",
    "    subset_rest_df=curr_city.loc[cat_match,:]  \n",
    "\n",
    "    subset_rest_df_rank=subset_rest_df.sort_values(by=['Num_Rev','Rating'],ascending=False).iloc[0:20,:]\n",
    "    rest_source = ColumnDataSource(data=dict(lat=subset_rest_df_rank.loc[:,'Lat'],lon=subset_rest_df_rank.loc[:,'Lng'],Name=subset_rest_df_rank.loc[:,'Name'],Rating=subset_rest_df_rank.loc[:,'Rating']))\n",
    "    rest_circle = Circle(x=\"lon\", y=\"lat\", size=5, fill_color=colors[0], fill_alpha=0.8, line_color='lightslategrey')\n",
    "    plot.add_glyph(rest_source, rest_circle)\n",
    "    hover = HoverTool( tooltips=[(\"Name\", \"@Name\"),('Rating','@Rating')])\n",
    "\n",
    "    plot.add_tools(PanTool(), WheelZoomTool(), BoxSelectTool(),ResetTool(),hover)\n",
    "\n",
    "\n",
    "    # Plot text rank\n",
    "    text_plot=rest_rank(subset_rest_df,novel_cats2[0].upper())\n",
    "\n",
    "    return plot,text_plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "visitor='San Diego'\n",
    "visited='New York'\n",
    "vis_plot=[]\n",
    "for freq in range(0,5):\n",
    "    curr_plot,curr_text=plot_same_map_clusters(visited,visitor,city_pair_kl,all_rest_df,eps_gen=eps_range[visited]['gen'],eps_clus=eps_range[visited]['clus'],num_freq=[freq],coords=city_locs[visited])\n",
    "    vis_plot.append([curr_plot,curr_text])\n",
    "vis_plot=gridplot(vis_plot)\n",
    "\n",
    "fname=visitor+'_'+visited+'_same_map'+'.html'\n",
    "full_name=os.path.join(foldname,fname)\n",
    "output_file(full_name)\n",
    "show(vis_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
